---
---

@string{aps = {American Physical Society,}}

@inproceedings{shan2020lcfi,
  abbr={LLVM},
  title={LCFI: A Fault Injection Tool for Studying Lossy Compression Error Propagation in HPC Programs},
  author={Shan, Baodi and Shamji, Aabid and Tian, Jiannan and Li, Guanpeng and Tao, Dingwen},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)},
  pages={2708--2715},
  year={2020},
  organization={IEEE},
  selected={true},
  bibtex_show={true},
  pdf={lcfi.pdf},
}

@InProceedings{10.1007/978-3-031-15922-0_2,
abbr="LLVM/OpenMP",
author="Lu, Wenbin
and Shan, Baodi
and Raut, Eric
and Meng, Jie
and Araya-Polo, Mauricio
and Doerfert, Johannes
and Malik, Abid M.
and Chapman, Barbara",
editor="Klemm, Michael
and de Supinski, Bronis R.
and Klinkenberg, Jannis
and Neth, Brandon",
title="Towards Efficient Remote OpenMP Offloading",
booktitle="OpenMP in a Modern World: From Multi-device Support to Meta Programming",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="17--31",
abstract="On modern heterogeneous HPC systems, the most popular way to realize distributed computation is the hybrid programming model of MPI+X (X being OpenMP/CUDA/etc.), as it has been proven to perform well with various scientific applications. However, application developers prefer to use a single coherent programming model over a hybrid model, as maintainability and portability decrease per additional model. Recent workÂ [14] has shown that the OpenMP device offloading model could be used to program distributed accelerator-based HPC systems with minimal changes to the application.",
isbn="978-3-031-15922-0",
bibtex_show={true},
selected={true},
pdf={iwomp22.pdf},
}

@inproceedings{10.1145/3582514.3582519,
author = {Shan, Baodi and Araya-Polo, Mauricio and Malik, Abid M. and Chapman, Barbara},
title = {MPI-Based Remote OpenMP Offloading: A More Efficient and Easy-to-Use Implementation},
year = {2023},
isbn = {9798400701153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582514.3582519},
doi = {10.1145/3582514.3582519},
abstract = {MPI+X is the most popular hybrid programming model for distributed computation on modern heterogeneous HPC systems. Nonetheless, for simplicity, HPC developers ideally would like to implement multi-node distributed parallel computing through a single coherent programming model. As de facto standard for parallel programming, OpenMP has been one of the most influential programming models in parallel computing. Recent work has proven that the OpenMP target offloading model could be used to program distributed accelerator-based HPC systems with marginal changes to the application. However, the UCX-based version of remote OpenMP offloading still has many limitations in terms of performance overhead and ease of use of the plugin.In this work, we have implemented a new MPI-based remote OpenMP offloading plugin. By comparing it with the UCX-based version, the new MPI-based plugin has been significantly improved in terms of performance, scalability, and ease of use. Evaluation of our work is conducted using one proxy-app, XSBench and an industrial-level seismic modeling code, Minimod. Results show that, compared to the optimized UCX-based version, our optimizations can reduce offloading latency by up to 70%, and raise application parallel efficiency by 68% when running with 16 GPUs on data-bound applications. In particular, the introduction of the concept of locality-aware offloading gives developers of HPC programs greater possibilities to take full advantage of modern hierarchical heterogeneous computing devices.},
booktitle = {Proceedings of the 14th International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = {50--59},
numpages = {10},
keywords = {OpenMP, distributed computing, GPGPU},
location = {Montreal, QC, Canada},
series = {PMAM'23}
}
